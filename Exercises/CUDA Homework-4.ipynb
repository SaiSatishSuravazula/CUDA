{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQSjG6xu7J0fEOoAwcKuwC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##4.1 Matrix Row/Column Sums\n","\n","Your first task is to create a simple matrix row and column sum application in CUDA. The code skeleton is already given to you in matrix_sums.cu. Edit that file, paying attention to the FIXME locations, so that the output when run is like this:\n","\n","```\n","row sums correct!\n","column sums correct!\n","```\n","\n","After editing the code, compile it using the following:\n","\n","```\n","module load cuda\n","nvcc -o matrix_sums matrix_sums.cu\n","```\n","\n","The module load command selects a CUDA compiler for your use. The module load command only needs to be done once per session/login. nvcc is the CUDA compiler invocation command. The syntax is generally similar to gcc/g++."],"metadata":{"id":"6ogBOqeh-Fg9"}},{"cell_type":"markdown","source":["### matrix_sums.cu\n","\n","```\n","#include <stdio.h>\n","\n","// error checking macro\n","#define cudaCheckErrors(msg) \\\n","    do { \\\n","        cudaError_t __err = cudaGetLastError(); \\\n","        if (__err != cudaSuccess) { \\\n","            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n","                msg, cudaGetErrorString(__err), \\\n","                __FILE__, __LINE__); \\\n","            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n","            exit(1); \\\n","        } \\\n","    } while (0)\n","\n","const size_t DSIZE = 16384;      // matrix side dimension\n","const int block_size = 256;  // CUDA maximum is 1024\n","\n","// matrix row-sum kernel\n","__global__ void row_sums(const float *A, float *sums, size_t ds){\n","\n","  int idx = FIXME // create typical 1D thread index from built-in variables\n","  if (idx < ds){\n","    float sum = 0.0f;\n","    for (size_t i = 0; i < ds; i++)\n","      sum += A[FIXME]         // write a for loop that will cause the thread to iterate across a row, keeeping a running sum, and write the result to sums\n","    sums[idx] = sum;\n","}}\n","\n","// matrix column-sum kernel\n","__global__ void column_sums(const float *A, float *sums, size_t ds){\n","\n","  int idx = FIXME // create typical 1D thread index from built-in variables\n","  if (idx < ds){\n","    float sum = 0.0f;\n","    for (size_t i = 0; i < ds; i++)\n","      sum += A[FIXME]         // write a for loop that will cause the thread to iterate down a column, keeeping a running sum, and write the result to sums\n","    sums[idx] = sum;\n","}}\n","\n","bool validate(float *data, size_t sz){\n","  for (size_t i = 0; i < sz; i++)\n","    if (data[i] != (float)sz) {printf(\"results mismatch at %lu, was: %f, should be: %f\\n\", i, data[i], (float)sz); return false;}\n","    return true;\n","}\n","\n","int main(){\n","\n","  float *h_A, *h_sums, *d_A, *d_sums;\n","  h_A = new float[DSIZE*DSIZE];  // allocate space for data in host memory\n","  h_sums = new float[DSIZE]();\n","    \n","  for (int i = 0; i < DSIZE*DSIZE; i++)  // initialize matrix in host memory\n","    h_A[i] = 1.0f;\n","    \n","  cudaMalloc(&d_A, DSIZE*DSIZE*sizeof(float));  // allocate device space for A\n","  FIXME // allocate device space for vector d_sums\n","  cudaCheckErrors(\"cudaMalloc failure\"); // error checking\n","    \n","  // copy matrix A to device:\n","  cudaMemcpy(d_A, h_A, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n","  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n","    \n","  //cuda processing sequence step 1 is complete\n","  row_sums<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_sums, DSIZE);\n","  cudaCheckErrors(\"kernel launch failure\");\n","  //cuda processing sequence step 2 is complete\n","    \n","  // copy vector sums from device to host:\n","  cudaMemcpy(h_sums, d_sums, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n","    \n","  //cuda processing sequence step 3 is complete\n","  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n","    \n","  if (!validate(h_sums, DSIZE)) return -1;\n","  printf(\"row sums correct!\\n\");\n","    \n","  cudaMemset(d_sums, 0, DSIZE*sizeof(float));\n","    \n","  column_sums<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_sums, DSIZE);\n","  cudaCheckErrors(\"kernel launch failure\");\n","  //cuda processing sequence step 2 is complete\n","    \n","  // copy vector sums from device to host:\n","  cudaMemcpy(h_sums, d_sums, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n","  //cuda processing sequence step 3 is complete\n","  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n","    \n","  if (!validate(h_sums, DSIZE)) return -1;\n","  printf(\"column sums correct!\\n\");\n","  return 0;\n","}\n","  \n","```"],"metadata":{"id":"H2c_m_X5-jkh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz57J_mT9mRz","executionInfo":{"status":"ok","timestamp":1741275492514,"user_tz":-330,"elapsed":425,"user":{"displayName":"Sai Satish Suravazula","userId":"07818230706550831173"}},"outputId":"30eeb8a3-68ba-4fb2-f9a8-024e4ee0835f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting matrix_sums.cu\n"]}],"source":["%%writefile matrix_sums.cu\n","\n","#include <stdio.h>\n","\n","// error checking macro\n","#define cudaCheckErrors(msg) \\\n","    do { \\\n","        cudaError_t __err = cudaGetLastError(); \\\n","        if (__err != cudaSuccess) { \\\n","            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n","                msg, cudaGetErrorString(__err), \\\n","                __FILE__, __LINE__); \\\n","            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n","            exit(1); \\\n","        } \\\n","    } while (0)\n","\n","const size_t DSIZE = 16384;      // matrix side dimension\n","const int block_size = 256;  // CUDA maximum is 1024\n","\n","// matrix row-sum kernel\n","__global__ void row_sums(const float *A, float *sums, size_t ds){\n","\n","  int idx = threadIdx.x + blockDim.x*blockIdx.x; // create typical 1D thread index from built-in variables\n","  if (idx < ds){\n","    float sum = 0.0f;\n","    for (size_t i = 0; i < ds; i++)\n","      sum += A[idx*ds+i];         // write a for loop that will cause the thread to iterate across a row, keeeping a running sum, and write the result to sums\n","    sums[idx] = sum;\n","}}\n","\n","// matrix column-sum kernel\n","__global__ void column_sums(const float *A, float *sums, size_t ds){\n","\n","  int idx = threadIdx.x + blockDim.x*blockIdx.x; // create typical 1D thread index from built-in variables\n","  if (idx < ds){\n","    float sum = 0.0f;\n","    for (size_t i = 0; i < ds; i++)\n","      sum += A[i*ds+idx];         // write a for loop that will cause the thread to iterate down a column, keeeping a running sum, and write the result to sums\n","    sums[idx] = sum;\n","}}\n","\n","bool validate(float *data, size_t sz){\n","  for (size_t i = 0; i < sz; i++)\n","    if (data[i] != (float)sz) {printf(\"results mismatch at %lu, was: %f, should be: %f\\n\", i, data[i], (float)sz); return false;}\n","    return true;\n","}\n","\n","int main(){\n","\n","  float *h_A, *h_sums, *d_A, *d_sums;\n","  h_A = new float[DSIZE*DSIZE];  // allocate space for data in host memory\n","  h_sums = new float[DSIZE]();\n","\n","  for (int i = 0; i < DSIZE*DSIZE; i++)  // initialize matrix in host memory\n","    h_A[i] = 1.0f;\n","\n","  cudaMalloc(&d_A, DSIZE*DSIZE*sizeof(float));  // allocate device space for A\n","  cudaMalloc(&d_sums, DSIZE*sizeof(float));// allocate device space for vector d_sums\n","  cudaCheckErrors(\"cudaMalloc failure\"); // error checking\n","\n","  // copy matrix A to device:\n","  cudaMemcpy(d_A, h_A, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n","  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n","\n","  //cuda processing sequence step 1 is complete\n","  row_sums<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_sums, DSIZE);\n","  cudaCheckErrors(\"kernel launch failure\");\n","  //cuda processing sequence step 2 is complete\n","\n","  // copy vector sums from device to host:\n","  cudaMemcpy(h_sums, d_sums, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n","\n","  //cuda processing sequence step 3 is complete\n","  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n","\n","  if (!validate(h_sums, DSIZE)) return -1;\n","  printf(\"row sums correct!\\n\");\n","\n","  cudaMemset(d_sums, 0, DSIZE*sizeof(float));\n","\n","  column_sums<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_sums, DSIZE);\n","  cudaCheckErrors(\"kernel launch failure\");\n","  //cuda processing sequence step 2 is complete\n","\n","  // copy vector sums from device to host:\n","  cudaMemcpy(h_sums, d_sums, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n","  //cuda processing sequence step 3 is complete\n","  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n","\n","  if (!validate(h_sums, DSIZE)) return -1;\n","  printf(\"column sums correct!\\n\");\n","  return 0;\n","}\n"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix_sums.cu -o matrix_sums"],"metadata":{"id":"HXlrlkKHFxdn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./matrix_sums"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4FZPP7dGOjG","executionInfo":{"status":"ok","timestamp":1741275501804,"user_tz":-330,"elapsed":2152,"user":{"displayName":"Sai Satish Suravazula","userId":"07818230706550831173"}},"outputId":"af3fb728-f61d-44d8-c5a3-3859dcde1534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["row sums correct!\n","column sums correct!\n"]}]}]}